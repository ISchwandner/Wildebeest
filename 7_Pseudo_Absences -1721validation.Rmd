---
title: "Pseudo_Absences"
author: "Imogen Schwandner -2671952S"
date: '2022-07-04'
output: html_document
---

1. Load libraries and required data

```{r}
library(sp)
library(adehabitatHR)
library(tidyverse)
library(dplyr)
library(plyr)
library(readr)
library(raster)
```

2. Load wildebeest data

```{r}
load("WB_and_Covariates_data.RData")

# remove covariates and other objects not needed here
rm(anthro, anthro1, D_river, D_roadT1, D_roadT5, D_wood, TWI, WB, WBS)
```

3. Create buffers around presence points to generate pseudo-absences within

Buffer size chosen as the maximum observed step length over 3 hour period for each animal in the data set

3.1. Calculate maximum 3h step length for each individual

```{r}
### 3.1.1. Load and reformat data
# convert spatial points object to data frame
WBH <- as.data.frame(WBH)

# reformat date column as POSIXct
WBH$datetime <- as.POSIXct(WBH$Date, format="%d/%m/%Y %H:%M", tz='GMT')

### 3.1.1. Create Trajectories
# convert points into a trajectory using 'adehabitat' package
WBtraj <- as.ltraj(cbind(WBH$x, WBH$y),date = WBH$datetime,id = (WBH$AID))

### 3.1.2. Create large combined trajectories data frame
# Create a data frame to holds all of the contents of WBtraj 
# Put first individual into the data frame
WBtraj.df <- data.frame(WBtraj[[1]], id = attr(WBtraj[[1]], "id"))

# Use a for loop to fill data frame with the rest of the trajectories
for(i in 2:length(WBtraj)) {
  WBtraj.df <- rbind(WBtraj.df, 
                    data.frame(WBtraj[[i]],
                    id = attr(WBtraj[[i]], "id")))
}

# remove NA's (final location has no distance displaced thereafter)
WBtraj.df <- subset(WBtraj.df, dist != "NA")

### 3.1.4. Maximum distance displaced over 3 h PER INDIVIDUAL
# Create object with individual ID and maximum distance displaced
indiv.max.dist <- WBtraj.df %>%
                  group_by(id) %>%
                  summarise(maxdist = max(dist))

#### if you ahve time check  why the above doesnt work but this does: 
#WBHind <- split(WBHind, WBtraj.df$id)

sizes <- c()
for(i in 1:length(WBHind)){
  maxdist <- max(WBHind[[i]]$dist)
  sizes <- c(sizes, maxdist)
} 

### 3.1.5. Create vector of individual buffer sizes
#sizes <- c(indiv.max.dist$maxdist)

```

3.2. Creating an individual buffer corresponding to the respective maximum observed step length over a 3 h interval for the availability points of each individual
```{r}
### 3.2.1. Re-project data and convert to spatialpoints df
coordinates(WBH) <- ~x+y
WBH@proj4string <- crs

### 3.2.2. Prepare data layout
# Split WBH into list of data frames for each individual
WBH_indiv <- split(WBH, WBH$AID)

# Create an empty list for the results
Buffer_list <- list()

### 3.2.3. Create individual buffers
# For loop to run through every animal in the list of individuals, to create a buffer with the extracted maximum observed step length corresponding to each individual
for (i in 1:length(sizes)) {
  
  #iterate through
  Buffer_list[[i]] <- rgeos::gBuffer(WBH_indiv[[i]], 
                                byid = TRUE, 
                                width = sizes[i])
}

### 3.2.4. Combine buffers into single object for sampling random absence points
# Bind list of polygons for each location together into one data frame per animal
for (i in 1:length(Buffer_list)) {
  Buffer_list[[i]] <- rbind(Buffer_list[[i]])
}

# Bind all animals together, to get one spatial polygons data frame with all buffers of all locations and all animals 

# Create data frame with animal one
Buffer_spdf <- Buffer_list[[1]]

# Fill data frame with all animals
for (i in 2:length(Buffer_list)) {
  Buffer_spdf <- rbind(Buffer_spdf, Buffer_list[[i]])
}
```

3.3. Generating 50 random points within each buffer as pseudo-absences

3.3.1. Sample 50 random points within each element of Buffer_spdf (each buffer of each location of each animal) for pseudo-absences
```{r}
# Create data frame with initial 50 points for first location of first animal
PA <- spsample(Buffer_spdf@polygons[[1]], n = 50, "random")

# Fill data frame with remaining points/locations/animals, however write these to file and clear the memory every 1000 points to improve run times
for (i in 2:length(Buffer_spdf@polygons)) {
  rp <- spsample(Buffer_spdf@polygons[[i]], n = 50, "random")

  if(is.null(PA)) {
    PA <- rp
  }else{
    PA <- rbind(PA, rp)
  }

   if(i/1000 == round(i/1000)| i==length(Buffer_spdf@polygons)) {
     print(i)
    write.csv(PA, paste0('./tempfilesPA/temp',i,'csv'), row.names=F)
    PA <- NULL

   }
}

### Combine tempfiles and write to data frame
# List files in directory
mydir <-  "tempfilesPA"
myfiles <-  list.files(path=mydir, pattern="*.csv", full.names=TRUE)
myfiles
# Read all files at once into single data frame
dat_csv <-  ldply(myfiles, read_csv)

```

3.3.2. Create data frame with AID and date and time column to add to random points for later covariate extraction

```{r}
# Create data frame with AID and datetime with 100 replications for each location, to then add coordinates of random points to for NDVI extraction
# For animal 1
DFF <- data.frame( "datetime" = rep(WBH@data[1, 22], 50), "AID" = rep(WBH@data[1, 1], 50))

# Loop for remaining animals, again writing every 1000 points to file and clearing memory to improve run times
for (i in 2:length(WBH@data$AID)) {
  DF <- data.frame( "datetime" = rep(WBH@data[i, 22], 50), "AID" = rep(WBH@data[i, 1], 50))
  
  if(is.null(DFF)) {
    DFF <- DF
  }else{
    DFF <- rbind(DFF, DF)
  }
  
  if(i/1000 == round(i/1000) | i==length((WBH@data$AID))) {
    print(i)
    write.csv(DFF, paste0('./tempfilesDFF/temp',i,'csv'), row.names =F)
    DFF <- NULL
  }
}

# Combine tempfiles and write to data frame
# List files in directory
dir <-  "tempfilesDFF"
files <-  list.files(path=dir, pattern="*.csv", full.names=TRUE)
files
# read all files at once into single data frame
data_csv <-  ldply(files, read_csv)

```

3.3.3. Combining Results from 3.3.2. into single data frame

```{r}
### Combine PA and DFF
Points <- cbind(data_csv, dat_csv)

### POINTS IS THE FINAL RESULT
save(Points, file = "Points1721.RData")
```

